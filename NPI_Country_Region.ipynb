{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NPI_Country_Region.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6-l2BWN4cwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" The codes for the projects were adapted from the https://github.com/siddk/npi \n",
        "This cell is for the data generation\"\"\"\n",
        "\n",
        "from generate_data import create_trace\n",
        "\n",
        "\n",
        "def create_data(train_samples_number = 30, test_samples_number = 16):\n",
        "    create_trace('train', train_samples_number)\n",
        "    create_trace('test', test_samples_number)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print('Creating data ...... ')\n",
        "    create_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bFhjC-J6G5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"This cell is for training\"\"\"\n",
        "from npi import NPI\n",
        "from f_encoder import F_Encoder\n",
        "from config import CONFIG, ScratchPad\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "INCREMENT = 1\n",
        "DATA_PATH = \"train.pik\"\n",
        "\n",
        "def train_model(epochs):\n",
        "    \"\"\"\n",
        "    Instantiates an Addition Core, NPI, then loads and fits model to data.\n",
        "\n",
        "    :param epochs: Number of epochs to train for.\n",
        "    \"\"\"\n",
        "    # Load Data\n",
        "    with open(DATA_PATH, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # Initialize Addition Core\n",
        "    print('Initializing Core!')\n",
        "    core = F_Encoder()\n",
        "\n",
        "    # Initialize NPI Model\n",
        "    print('Initializing NPI Model!')\n",
        "    npi = NPI(core, CONFIG)\n",
        "\n",
        "    # Initialize TF Saver\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    # Initialize TF Session\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "\n",
        "    # Start Training\n",
        "    training_error = {}\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        print(ep)\n",
        "        training_error[ep] = []\n",
        "        for i in range(len(data)):\n",
        "            # Reset NPI States\n",
        "            npi.reset_state()\n",
        "\n",
        "            # Setup Environment\n",
        "            c_find, steps = data[i]\n",
        "            scratch = ScratchPad(c_find)\n",
        "            x, y = steps[:-1], steps[1:]\n",
        "           # Run through steps, and fit!\n",
        "            step_def_loss, term_acc, prog_acc, = 0.0, 0.0, 0.0\n",
        "\n",
        "            for j in range(len(x)):\n",
        "                (prog_name, prog_in_id), arg, term = x[j]\n",
        "                (_, prog_out_id), arg_out, term_out = y[j]\n",
        "\n",
        "                if prog_in_id == 1:\n",
        "                    scratch.increment_ptr()\n",
        "                # Get Environment, Argument Vectors\n",
        "                env_in = [scratch.get_env()]\n",
        "                # arg_in, arg_out = [get_args(arg, arg_in=True)], get_args(arg_out, arg_in=False)\n",
        "                prog_in, prog_out = [[prog_in_id]], [prog_out_id]\n",
        "                term_out = [1] if term_out else [0]\n",
        "\n",
        "                # Fit!\n",
        "                loss, t_acc, p_acc, _ = sess.run(\n",
        "                        [npi.default_loss, npi.t_metric, npi.p_metric, npi.default_train_op],\n",
        "                        feed_dict={npi.env_in: env_in,  npi.prg_in: prog_in,\n",
        "                                   npi.y_prog: prog_out, npi.y_term: term_out})\n",
        "                step_def_loss += loss\n",
        "                term_acc += t_acc\n",
        "                prog_acc += p_acc\n",
        "\n",
        "            training_error[ep].append((i, step_def_loss / len(x), term_acc / len(x), prog_acc / len(x)))\n",
        "    # Save Model\n",
        "    print(\"Epoch {} Step {} Default Step Loss {},Term: {}, Prog: {}\".format(ep, i, step_def_loss / len(x), term_acc / len(x), prog_acc / len(x)))\n",
        "\n",
        "    saver.save(sess, 'model/model.ckpt')\n",
        "    return training_error\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    training_error = train_model(epochs=30)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEBVzvYZ_bJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Plotting\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(rc={'figure.figsize':(7,5)})\n",
        "\n",
        "# plot first epoch\n",
        "err1 = training_error[1]\n",
        "err5 = training_error[5]\n",
        "err10 = training_error[30]\n",
        "\n",
        "step_def_loss1 = [i[1] for i in err1]\n",
        "prog_acc1 = [i[2] for i in err1]\n",
        "term_acc1 = [i[3] for i in err1]\n",
        "\n",
        "step_def_loss5 = [i[1] for i in err5]\n",
        "prog_acc5 = [i[2] for i in err5]\n",
        "term_acc5 = [i[3] for i in err5]\n",
        "\n",
        "step_def_loss10 = [i[1] for i in err10]\n",
        "prog_acc10 = [i[2] for i in err10]\n",
        "term_acc10 = [i[3] for i in err10]\n",
        "\n",
        "data = [i[0] for i in err1]\n",
        "epoch_labels = {0: 1, 1: 5, 2:30}\n",
        "\n",
        "y = [step_def_loss1, step_def_loss5, step_def_loss10]\n",
        "plt.xlabel(\"Data trace num\")\n",
        "plt.ylabel(\"Step default loss\")\n",
        "for i in range(len(y)):\n",
        "    plt.plot(data,y[i],label = 'epoch %s'% epoch_labels[i])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8MtVBSkFThq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Plotting\"\"\"\n",
        "y = [prog_acc1, prog_acc5, prog_acc10]\n",
        "plt.xlabel(\"Data trace num\")\n",
        "plt.ylabel(\"Program accuracy\")\n",
        "for i in range(len(y)):\n",
        "    plt.plot(data,y[i],label = 'epoch %s'% epoch_labels[i])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OaRa7pME73J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Plotting\"\"\"\n",
        "y = [term_acc1, term_acc5, term_acc10]\n",
        "plt.xlabel(\"Data trace num\")\n",
        "plt.ylabel(\"Termination accuracy\")\n",
        "for i in range(len(y)):\n",
        "    plt.plot(data,y[i],label = 'epoch %s'%epoch_labels[i])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej4JxsQCBvph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" This cell is for testing \"\"\"\n",
        "from npi import NPI\n",
        "from f_encoder import F_Encoder\n",
        "from config import CONFIG, PROGRAM_SET, ScratchPad, COUNTRY_REGION, NUM_CODE, COUNTRY_REGION_CODE\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "CKPT_PATH = \"model/model.ckpt\"\n",
        "TEST_PATH = \"test.pik\"\n",
        "\n",
        "def evaluate():\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        # Load Data\n",
        "        with open(TEST_PATH, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        # Initialize Core\n",
        "        core = F_Encoder()\n",
        "\n",
        "        # Initialize NPI Model\n",
        "        npi = NPI(core, CONFIG)\n",
        "\n",
        "        # Restore from Checkpoint\n",
        "        saver = tf.train.Saver()\n",
        "        saver.restore(sess, CKPT_PATH)\n",
        "\n",
        "        # Run REPL\n",
        "        repl(sess, npi, data)\n",
        "\n",
        "\n",
        "def repl(session, npi, data):\n",
        "    while True:\n",
        "        inpt = input('Hit Enter for Random country: ')\n",
        "\n",
        "        if inpt == \"\":\n",
        "            x = data[np.random.randint(len(data))][0]\n",
        "\n",
        "        else: \n",
        "          break\n",
        "          \n",
        "        print('To find: ', COUNTRY_REGION_CODE[x])\n",
        "        # Reset NPI States\n",
        "        print(\"\")\n",
        "        npi.reset_state()\n",
        "\n",
        "        # Setup Environment\n",
        "        scratch = ScratchPad(x)\n",
        "        prog_name, prog_id, arg, term = 'FIND', 0, [], False\n",
        "        print('--------  Environment ----------' )\n",
        "        scratch.pretty_print()\n",
        "        print('-----------------------------------')\n",
        "        cont = 'c'\n",
        "        while cont == 'c' or cont == 'C':\n",
        "            a_str = \"[]\"\n",
        "\n",
        "            print('Step: %s, Arguments: %s, Terminate: %s' % (prog_name, a_str, str(term)))\n",
        "            \n",
        "            if prog_id == 1:\n",
        "                scratch.increment_ptr()\n",
        "\n",
        "            \n",
        "            env_in, prog_in = [scratch.get_env()],  [[prog_id]]\n",
        "\n",
        "            t, n_p = session.run([npi.terminate, npi.program_distribution],\n",
        "                                         feed_dict={npi.env_in: env_in,\n",
        "                                                    npi.prg_in: prog_in})\n",
        "            if np.argmax(t) == 1:\n",
        "                print('Step: %s, Arguments: %s, Terminate: %s' % (prog_name, a_str, str(True)))\n",
        "\n",
        "                scratch.pretty_print()\n",
        "\n",
        "                true_ans = None\n",
        "                for i in COUNTRY_REGION:\n",
        "                  if i[0] == x:\n",
        "                      true_ans = COUNTRY_REGION_CODE[i[1]]\n",
        "                      break\n",
        "                if(scratch.ptr<scratch.rows-1):\n",
        "                    output = COUNTRY_REGION_CODE[scratch[scratch.ptr][1]]\n",
        "                    scratch[scratch.rows-1][0] = NUM_CODE[output]\n",
        "                else:\n",
        "                    output = 'Not found'\n",
        "                \n",
        "                print('Pointer at ', scratch.ptr)\n",
        "                print('-------- KB Environment ----------' )\n",
        "                scratch.pretty_print()\n",
        "                print('-'*100)\n",
        "                print(\"Model Output: \", output)\n",
        "                print(\"Correct Out : \" , true_ans)\n",
        "                print(\"Correct!\" if output == true_ans else \"Incorrect!\")\n",
        "\n",
        "            else:\n",
        "                prog_id = np.argmax(n_p)\n",
        "                prog_name = PROGRAM_SET[prog_id][0]\n",
        "                term = False\n",
        "\n",
        "            cont = input('Continue? enter \"c\"')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umIGbsGsld3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}